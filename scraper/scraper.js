// import * as cheerio from "cheerio";
// import cron from "node-cron";
// import axios from "axios";
// import { connectDB } from "../backend/src/config/db.js";
// import { bookModel } from "../backend/src/dbSchema.js"; 
// import dotenv from "dotenv";

// dotenv.config();

// const BASE_URL = "https://books.toscrape.com/catalogue/";
// const ratingMap = { One: 1, Two: 2, Three: 3, Four: 4, Five: 5 };

// export async function scrapeBooks() {
//   await connectDB(); // Ensure DB connection

//   try {
//     let nextPage = "page-1.html";

//     while (nextPage) {
//       console.log(`üìñ Scraping: ${BASE_URL + nextPage}`);

//       const { data } = await axios.get(BASE_URL + nextPage);
//       const $ = cheerio.load(data);
//       const booksOnPage = $(".product_pod");

//       for (let i = 0; i < booksOnPage.length; i++) {
//         const el = booksOnPage[i];

//         const title = $(el).find("h3 a").attr("title");
//         const price = parseFloat($(el).find(".price_color").text().replace("¬£", ""));
//         const availability = $(el).find(".availability").text().includes("In stock") ? "In stock" : "Out of stock";
//         const ratingClass = $(el).find(".star-rating").attr("class").split(" ")[1];
//         const rating = ratingMap[ratingClass] || 0;
//         const detailPageUrl = BASE_URL + $(el).find("h3 a").attr("href");
//         const thumbnailUrl = "https://books.toscrape.com/" + $(el).find("img").attr("src").replace("../", "");

//         await bookModel.updateOne(
//           { title },
//           { title, price, availability, rating, detailPageUrl, thumbnailUrl },
//           { upsert: true }
//         );
//       }

//       const next = $(".next a").attr("href");
//       nextPage = next ? next : null;
//     }

//     console.log("üéâ Scraping completed!");
//   } catch (err) {
//     console.error("‚ùå Scraping failed:", err.message);
//     throw err; // so the endpoint knows it failed
//   }
// }

// // Optional: keep the cron job for automatic daily scraping
// cron.schedule("0 0 * * *", async () => {
//   console.log("‚è∞ Cron Job Triggered - running scraper...");
//   await scrapeBooks();
// });


// scraper/scraper.js
// scraper/scraper.js
const cheerio = require("cheerio");
const axios = require("axios");
const { connectDB } = require("../backend/src/config/db.js");
const { bookModel } = require("../backend/src/dbSchema.js");
require("dotenv").config();

const BASE_URL = "https://books.toscrape.com/catalogue/";
const ratingMap = { One: 1, Two: 2, Three: 3, Four: 4, Five: 5 };

async function scrapeBooks() {
  await connectDB();
  try {
    let nextPage = "page-1.html";

    while (nextPage) {
      console.log(`üìñ Scraping: ${BASE_URL + nextPage}`);
      const { data } = await axios.get(BASE_URL + nextPage);
      const $ = cheerio.load(data);

      const booksOnPage = $(".product_pod");
      for (let i = 0; i < booksOnPage.length; i++) {
        const el = booksOnPage[i];
        const title = $(el).find("h3 a").attr("title");
        const price = parseFloat($(el).find(".price_color").text().replace("¬£", ""));
        const availability = $(el).find(".availability").text().includes("In stock") ? "In stock" : "Out of stock";
        const ratingClass = $(el).find(".star-rating").attr("class").split(" ")[1];
        const rating = ratingMap[ratingClass] || 0;
        const detailPageUrl = BASE_URL + $(el).find("h3 a").attr("href");
        const thumbnailUrl = "https://books.toscrape.com/" + $(el).find("img").attr("src").replace("../", "");

        await bookModel.updateOne(
          { title },
          { title, price, availability, rating, detailPageUrl, thumbnailUrl },
          { upsert: true }
        );
      }

      const next = $(".next a").attr("href");
      nextPage = next ? next : null;
    }

    console.log("üéâ Scraping completed!");
  } catch (err) {
    console.error("‚ùå Scraping failed:", err.message);
    throw err;
  }
}

// Export the function for backend /refresh
module.exports = { scrapeBooks };

// ===============================
// Run manually only if this file is executed directly
if (require.main === module) {
  (async () => {
    console.log("‚è≥ Manual scrape started...");
    try {
      await scrapeBooks();
      console.log("‚úÖ Manual scrape finished!");
      process.exit(0);
    } catch (err) {
      console.error("‚ùå Manual scrape failed:", err);
      process.exit(1);
    }
  })();
}
